/* Sun-$Revision: 30.18 $ */

/* Copyright 1992-2012 AUTHORS.
   See the LICENSE file for license information. */

# pragma implementation  "nmethod.hh"
# pragma implementation  "nmethod_inline.hh"

# include "_nmethod.cpp.incl"

# if  defined(FAST_COMPILER) || defined(SIC_COMPILER)

VtblPtr_t   nmethod::_vtbl_value;

#define FOR_MY_CODETABLE_ENTRIES(e) \
 for (codeTableEntry *e= codeTableLink;  e;  e= e->next_nm)

static char* iAddr;             // gross hack for 2.0 allocator
static nmethodScopes* sAddr;
static addrDesc* lAddr;
static nmln* dAddr;

static int32 iLen;              // this is even grosser because g++ doesnt
static int32 ilLen;             // eat stuff like "new(7) Y(foo)"
static int32 sLen;
static nmln* depsStart;
static nmln* depsEndArg;
static int32 dLen;

nmethod* nmethod::new_nmethod(AbstractCompiler* c, bool generateDebugCode) {
  // This grossness is brought to you by the great way in which C++
  // handles non-standard allocation...
  Assembler* instsA = c->instructions();
  iLen  = roundTo(instsA->instsEnd - instsA->instsStart, oopSize);
  ilLen = (char*) instsA->locsEnd - (char*) instsA->locsStart;

  sLen = c->scopeDescRecorder()->size();

  depsStart = c->L->deps->start();
  depsEndArg = c->L->deps->end();
  dLen = (char*) depsEndArg - (char*) depsStart;

  // This assertion is tempting, but zombie nmethods created in the conversion
  // break it because they are obsolete.
  // A dependency from the method to the nmethod would be cleaner, but
  // would take more space -- dmu 7/39
  //  
  //  assert (      dLen > 0
  //            ||  c->L->selector == VMString[DO_IT],
  //          "all nmethods must have some dependencies");
  
  nmethod* nm = new nmethod(c, generateDebugCode);
  Memory->code->used_per_compiler[c->nmName()] += nm->size();
  return nm;
}

void* nmethod::operator new(size_t size) {
  Unused(size);
  void* p;
  fint  number_of_tries = 0;

  // if we're really low on space - try once more (out-of-space detection in
  // zone is too complicated to get 100% right)
  while( number_of_tries++ < 2) {
    p = Memory->code->alloc(iLen, sLen, ilLen, dLen + sizeof(nmethod*),
                            iAddr, sAddr, lAddr, dAddr);
    if (p != 0) {
      return p;
    }
  }
  fatal("Couldn't flush enough methods from the code cache.\n"
        "You should increase the size of the code cache by writing\n"
        "a snapshot with code_size increased (see the documentation\n"
        "for _MemoryWriteSnapshot:Compress:Sizes:).");
  return p; // Was 0, but gcc3 complains
}

nmethod::nmethod(AbstractCompiler* c, bool generateDebugCode) {
  CHECK_VTBL_VALUE;
  _instsLen  = roundTo(iLen, oopSize);
  _locsLen   = ilLen;
  depsLen    = dLen;
  // backpointer is just before deps
  depsAddr   = (nmln*)     ((char*)dAddr + sizeof(nmethod*));

  *dBackLinkAddr() = this;
  
  // Copy the nmethodScopes scopeDescs generated by the ScopeDescRecorder
  // to the allocation area.
  c->scopeDescRecorder()->copyTo((VtblPtr_t*)sAddr, (int32)this);
  
  this->scopes = (nmethodScopes*) sAddr;

  oldCount = 0;
  flags.clear();
  flags.isDebug = generateDebugCode;
  setCompiler(c->name());
  flags.isUncommonRecompiled = currentProcess->isUncommon();
    
  verifiedOffset      = c->verifiedOffset();
  diCheckOffset       = c->diCheckOffset();

  frameCreationOffset = c->frameCreationOffset();
  
  rememberLink.init();
  codeTableLink= 0;
  diLink.init(c->diLink);
  if (diLink.notEmpty()) flags.isDI = true;
  flags.level = c->level();
  if (flags.level >= MaxRecompilationLevels) { // added = zzzz
    warning1("setting invalid nmethod level %x", flags.level);  // fix this
    flags.level = 0;
  }
  flags.version = c->version();
  if (c->nmName() == nm_nic && ((FCompiler*)c)->isImpure)
    makeImpureNIC();
  key.set_from(c->L->key);
  check_store();
  
  clear_frame_chain();
  assert(c->frameSize() >= 0, "frame size cannot be negative");
  frame_size = c->frameSize();
  _incoming_arg_count = c->incoming_arg_count();
  get_platform_specific_data(c);

  Assembler* instsA = c->instructions();
  copy_bytes(        instsA->instsStart,        insts(), instsLen());
  copy_words((int32*)instsA->locsStart,  (int32*)locs(),  ilLen/4);
  copy_words((int32*)depsStart,          (int32*)deps(),  depsLen/4);
  
  addrDesc *l, *lend;
  for (l = locs(), lend = locsEnd(); l < lend; l++) {
    l->initialShift(this, (char*)insts() - (char*)instsA->instsStart, 0);
  }

  char* bound = Memory->new_gen->boundary();
  for (l = locs(), lend = locsEnd(); l < lend; l++) {
    if (l->isOop())
      OopNCode::check_store(oop(l->referent(this)), bound); // cfront garbage
    else if (l->isSendDesc()) {
      l->asSendDesc(this)->dependency()->init();
    } else if (l->isDIDesc()) {
      l->asDIDesc(this)->dependency()->init();
      flags.isDI = true; 
    }
  }
  
  for (nmln* d = deps(), *dend = depsEnd(); d < dend; d++) {
    d->relocate();
  }
  
  MachineCache::flush_instruction_cache_range(insts(), instsEnd());
  MachineCache::flush_instruction_cache_for_debugging();
  
  if (this == (nmethod*)catchThisOne) warning("caught nmethod");
}

char* nmethod::entryPointFor(sendDesc *sd) {
  if (sd->pic()) return verifiedEntryPoint();
  bool rcvrStaticLookupType= sd->lookupType() & ReceiverStaticBit;
  if (!rcvrStaticLookupType) return insts();
  return ReuseNICMethods && findNMethod(sd)->reusable()
          ? insts() : verifiedEntryPoint();
}

fint nmethod::level() {
  assert(flags.level < MaxRecompilationLevels,  "invalid level"); // zzzz
  return flags.level;
}

void nmethod::setVersion(fint v) {
  assert(v > 0 && v <= MaxVersions, "bad version");
  flags.version = v;
}

ScopeDesc* nmethod::containingScopeDesc(char* pc) {
  return containingPcDesc(pc)->containingDesc(this);
}

void nmethod::check_store() {
  if (key.is_new() || scopes->is_new()) {
    remember();
    return;
  }
  FOR_MY_CODETABLE_ENTRIES(e)
    if (e->key.is_new()) {
      remember();
      return;
    }
}

void nmethod::moveTo_inner(NCodeBase* p, int32 delta, int32 size) {
  nmethod* to = (nmethod*)p;
  if (this == to) return;
  if (PrintCodeCompaction) {
    lprintf("*moving nmethod %#lx (", this);
    printName(0, key.selector);
    lprintf(") to %#lx\n", to);
  }

  OopNCode::moveTo_inner(to, delta, size);

  assert(iabs((char*)to - (char*)this) >= sizeof(NCodeBase),
         "nmethods overlap too much");
  assert(sizeof(NCodeBase) % oopSize == 0, "should be word-aligned");
  // init to's vtable
  copy_words((int32*)this, (int32*)to, sizeof(NCodeBase) / sizeof(int32));

  scopes->_nmethod_backPointer = to;
  *dBackLinkAddr() = to;
  flatProfiler->move(insts(), instsEnd(), to->insts());
  
  zoneLink.shift(delta);
  
  FOR_MY_CODETABLE_ENTRIES(e) {
    e->nm= to;
  }

  for (nmln *x = linkedSends.next, *y = x->next;
       x != &linkedSends;
       x = y, y = y->next) {
    NCodeBase* s = findThing(x);
    s->shift_target(x, delta);
  }
  linkedSends.shift(delta, this);
  
  if (diLink.notEmpty()) {
    assert(diLink.next->next == &diLink, "diLink should be a pair");
    diLink.next->asDIDesc()->shift_jump_addr(delta);
  }
  diLink.shift(delta);
  
  for (addrDesc* q = locs(), *pend = locsEnd(); q < pend; q++) {
    if (q->isSendDesc()) {
      sendDesc* sd = q->asSendDesc(this);
      sd->shift(delta, this);
    }
    else if (q->isDIDesc()) {
      nmln* l = q->asDIDesc(this)->dependency();
      l->shift(delta);
    }
    q->shift(this, delta);
  }
  if (frame_chain != NoFrameChain && frame_chain != SavedFrameChain)
    frame_chain->nmethod_moved_by(delta, this);
}


void nmethod::shift_target(nmln* l, int32 delta) {
  l->asSendDesc()->shift_jump_addr(delta);
}

NCodeBase* nmethod::unlink_me(nmln* l) {
  l->asSendDesc()->unlink();
  return this;
}


void nmethod::addDeps(dependencyList *dl) {
  nmln *d;
  for (d= dl->start();  d < dl->end();  d++) {
    for (nmln *p= d->next;  p != d;  p= p->next)
      if (p >= deps() && p < depsEnd()) {
        // nmethod already on this list
        p->remove();
        break;
      }
  }
  for (nmln *nd= deps();  nd < depsEnd();  nd++)
    if (nd->notEmpty()) {
      dl->add(nd);  // could make this a shade more efficient by adding
                    // a function to dependencyList
      nd->remove();
    }
  fint ndeps= dl->length();
  if (ndeps == depsEnd() - deps()) {
    // no need to allocate new region, just copy
    copy_words((int32*)dl->start(), (int32*)deps(), depsLen / sizeof(nmln*));
    for (d= deps();  d < depsEnd();  d++)
      d->relocate();
    return;
  }
  assert(ndeps > depsEnd() - deps(), "deps didn't grow!");
  // now make dl the method's deps
  fint newDepsLen= ndeps * sizeof(nmln);
  char *dAddr= Memory->code->allocateDeps(newDepsLen + sizeof(nmethod*));
  nmln *newDeps= (nmln*) (dAddr + sizeof(nmethod*));
  copy_words((int32*)dl->start(), (int32*)newDeps, newDepsLen / sizeof(nmln*));
  for (d= newDeps;  d < newDeps + ndeps;  d++)
    d->relocate();
  Memory->code->deallocateDeps((char*)dBackLinkAddr(),
                               depsLen + sizeof(nmethod*));
  depsAddr= newDeps;
  depsLen= newDepsLen;
  *dBackLinkAddr()= this;
}


void nmethod::moveDeps(nmln* newDeps, int32 delta) {
  for (nmln* d = deps(), *dend = depsEnd(); d < dend; d++) {
    d->shift(delta);
  }
  depsAddr = newDeps;
}

void nmethod::moveScopes(nmethodScopes* s) {
  // currently, the scopes & pcs are position-independent
  scopes = s;
}


void nmethod::remove_me_from_inline_cache() {
  static int n = 0;
  while (linkedSends.notEmpty()) {
    nmln *x= linkedSends.next;
    assert(x->next != 0, "");
    findThing(x)->unlink_me(x);
  }
}


void nmethod::makeYoung() {
  // Relink nm into its callers; aging stubs will be inserted.
  // The agingLimit will be set to 1 because of nm's trapCount.
  assert(!isYoung(), "why call this?");
  flags.isYoung= 1;
  nmln *lnext;
  for (nmln* l= linkedSends.next;  l != &linkedSends; l= lnext) {
    lnext= l->next; // because we're mutating l
    sendDesc* sd= l->asSendDesc_or_null();
    if (sd)
      sd->rebind(this, 0);
    else {
      CacheStub *pic= l->asCacheStub();
      if (pic)
        pic->rebind(l, this, 0);
    }
  }
}


void nmethod::makeVeryYoung() {
  assert(isYoung(), "not young enough");
  // reset limits of aging stubs to 1 to provoke recompilation
  for (nmln* l= linkedSends.next;  l != &linkedSends;  l= l->next) {
    CountStub* cs= l->asCountStub();
    if (cs && cs->isAgingStub())
      // NB: in (rare) cases, may not have an aging stub
      ((AgingStub*)cs)->init(this);     // sets limit to 1
  }
}


void nmethod::makeOld() {
  flags.isYoung= 0;
  // remove all AgingStubs
  nmln* nextl;
  for (nmln* l= linkedSends.next;  l != &linkedSends;  l= nextl) {
    nextl= l->next;             // because we're mutating l
    NCodeBase* s= findThing(l);
    if (s->isAgingStub()) {
      AgingStub *a= (AgingStub*)s;
      sendDesc* sd= a->sd();
      if (sd) {
        a->deallocate();
        sd->setCounting(NonCounting);
        sd->rebind(this);
      } else {
        CacheStub *pic= a->pic();
        assert(pic, "no pic for sendDesc");
        pic->rebind(a->sdLink.next, this, 0);
        a->deallocate();
      }
    }
  }
}


fint nmethod::agingLimit() {
# ifdef SIC_COMPILER
  // use exponential back-off for limit
  if (flags.trapCount > MapLoadTrapLimit) {
    // not really a young method, but has trapping map loads and thus needs
    // to be recompiled
    return 1;
  } else if (isUncommonRecompiled()) { 
    fint limit = MaturityInvocationLimit;
    for (fint i = 1; i < version(); i++) limit *= MaturityScalingFactor;
    return min(limit, 100000);
  } else {
    return MaturityInvocationLimit;
  }
# else
  return 17;
# endif
}



void nmethod::forwardLinkedSends(nmethod* to) {
  // the to nmethod is about to replace the receiver; replace receiver in
  // all inline caches
  if (key.receiverMapOop() != to->key.receiverMapOop()) {
    // receiver map has changed - either through programming or because
    // a block map has changed -- don't forward (too complicated e.g. if
    // called by CountStub via a PIC)
    return;
  }
  while(linkedSends.notEmpty()) {
    nmln *x = linkedSends.next;
    findThing(x)->forwardLinkedSend(x, to);
  }
}

void nmethod::removeFromCodeTable() {
  codeTableEntry *nexte;
  for (codeTableEntry *e= codeTableLink;  e;  e= nexte) {
    nexte= e->next_nm;
    e->next_hash.remove();
    delete e;
  }
  codeTableLink= 0;
}


int nmethodFlushCount = 0;

void nmethod::unlink() {
  removeFromCodeTable();
  zoneLink.remove();
  remove_me_from_inline_cache();
  
  if (diLink.notEmpty()) {
    assert(diLink.next->next == &diLink, "should only be a pair on a diLink");
    diLink.next->asDIDesc()->unlink_me();
  }
  
  for (nmln* d = deps(), *dend = depsEnd(); d < dend; d++) {
    d->remove();
  }

  MachineCache::flush_instruction_cache_for_debugging();
}


// I believe there is a bug here--the original comment in nmethod::flush
// where makeZombie is called with a false argument
// says don't unlink(), but I think it should stil be unlinked from codeTable.
// Otherwise the assertion in CodeTable::lookup about duplicate nmethods trips.
// I cannot see why it should be left in the table anyway.
// So I added the call to removeFromCodeTable() below.
// -- dmu 1/12/03

void nmethod::makeZombie(bool unlnk) {
  // mark this nmethod as zombie (it is almost dead and can be flushed as
  // soon as it is no longer on the stack)
  if (!isZombie()) {
    flags.isZombie = 1;
    flags.isToBeRecompiled = 0;
    if (unlnk) unlink();
    else       removeFromCodeTable(); // added by dmu 1/03; see comment in nmethod::flush
    zoneLink.remove();
    Memory->code->zombies.add(&zoneLink);
  }
}

void nmethod::flush() {
  BlockProfilerTicks bpt(exclude_nmethod_flush);
  CSect cs(profilerSemaphore);          // for profiler
# if GENERATE_DEBUGGING_AIDS
    if (CheckAssertions) {
      // for debugging
      if (nmethodFlushCount  &&  --nmethodFlushCount == 0)
        warning("nmethodFlushCount");
      if (this == (nmethod*)catchThisOne) warning("caught nmethod");
    }
# endif
  
  // EventMarker em("flushing nmethod %#lx %s", this, "");
  if (PrintMethodFlushing) {
    ResourceMark m;
    char *compilerName = VMString[compiler()]->copy_null_terminated();
    lprintf("*flushing %s%s%s-nmethod 0x%lx %d\t(",
           isZombie() ? "zombie " : "", 
           isAccess() ? "access " : "",
           compilerName, (void*)(long unsigned)this, (void*)useCount[id]);
    printName(0, key.selector);
    lprintf(")");
  }

  // always check the following - tests are really cheap
  if (flags.flushed) fatal1("nmethod %#lx already flushed", this);
  if (zone::frame_chain_nesting == 0) fatal("frames must be chained when flushing");

  if (frame_chain != NoFrameChain) {
    // Can't remove an nmethod from deps chains now, because later
    // programming changes may need to invalidate it.
    // That is, don't unlink() now.
   
    // See comment for makeZombie routine. The comment above is the 
    // "original comment" referred to there.
    // -- dmu 1/12/03

    if (this == recompilee) {
      // nmethod is being recompiled; cannot really flush yet
      // em.event.args[1] = "(being recompiled)";
      if (PrintMethodFlushing) {
        lprintf(" (being recompiled)\n");
      }
    } else {
      // nmethod is currently being executed; cannot flush yet
      // em.event.args[1] = "(currently active)";
      if (PrintMethodFlushing) {
        lprintf(" (currently active)\n");
      }
    }
    makeZombie(false);
  } else {
    unlink();
  
    // nmethod is not being executed; completely throw away
    // em.event.args[1] = "(not currently active)";
    if (PrintMethodFlushing) {
      lprintf("\n");
    }
    flatProfiler->flush((char*)this, instsEnd());
    zoneLink.remove();
    rememberLink.remove();
    for (addrDesc* p = locs(), *pend = locsEnd(); p < pend; p++) {
      if (p->isSendDesc()) {
        p->asSendDesc(this)->unlink();
      } else if (p->isDIDesc()) {
        p->asDIDesc(this)->dependency()->flush();
      }
    }
    flags.flushed = 1;                        // to detect flushing errors
#   if GENERATE_DEBUGGING_AIDS
    if (CheckAssertions) {
      set_oops((oop*)insts(), instsLen()/oopSize, 0); // for quicker detection
    }
#   endif
    Memory->code->free_nmethod(this);
  }
  MachineCache::flush_instruction_cache_for_debugging();
}


void nmethod::flushPartially() {
# ifdef SIC_COMPILER
  oldCount = min(recompileLimit(level()), invocationCount());
# else
  oldCount = invocationCount();
# endif
  useCount[id] = 0;
  removeFromCodeTable();
  diLink.remove();
  save_unlinked_frame_chain();  // protect from accidental flushing
  if (!UsePICRecompilation) {
    flush();                    // also flush the inline caches
  }
  assert(frame_chain != NoFrameChain, "frames should be chained now");
}





void nmethod::invalidate() {
  if (isInvalid()) return;
  processes->needsInvalidate = true;
# if GENERATE_DEBUGGING_AIDS
    if (CheckAssertions  &&  this == (nmethod*)catchThisOne) warning("caught nmethod");
# endif
  
  if (PrintMethodInvalidation) {
    lprintf("*invalidating nmethod 0x%lx (", (void*)this);
    printName(0, key.selector);
    lprintf(")\n");
  }
  
  LOG_EVENT1("invalidating nmethod %#lx", this);
  flags.isInvalid = true;
  unlink();
}

#ifdef UNUSED
// remove this methods PICs; return total size of flushed PICs
int32 nmethod::flushPICs() {
  int32 flushed = 0;
  for (addrDesc* p = locs(), *pend = locsEnd(); p < pend; p++) {
    if (p->isSendDesc()) {
      sendDesc* sd = p->asSendDesc(this);
      CacheStub* s = sd->pic();
      if (s) {
        flushed += s->size();
        s->deallocate();
      }
    }
  }
  MachineCache::flush_instruction_cache_for_debugging();
  return flushed;
}
#endif

#ifdef UNUSED
// unlink di Links and save them 
int32 nmethod::unlinkDI(nmln*& savedDIChildren) {
  int32 nlinks = 0;
  savedDIChildren = NEW_RESOURCE_ARRAY(nmln, locsEnd() - locs());
  for (addrDesc* p = locs(), *pend = locsEnd(); p < pend; p++) {
    if (p->isDIDesc()) {
      nmln* l = p->asDIDesc(this)->dependency();
      savedDIChildren[nlinks].init();
      if (l->notEmpty()) {
        assert(l->next->next == l, "should be a pair");
        l->next->rebind(&savedDIChildren[nlinks]);
        assert(savedDIChildren[nlinks].notEmpty(), "should have saved link");
      }
      assert(p->asDIDesc(this)->dependency()->isEmpty(),
             "should be empty now");
      nlinks++;
    }
  }
  return nlinks;
}
#endif

# ifdef brokenDI        // DI recompilation is currently broken
void nmethod::relinkDI(int32 n, nmln*& savedDIChildren) {
  Unused(n);
  int32 nlinks = 0;
  for (addrDesc* p = locs(), *pend = locsEnd(); p < pend; p++) {
    if (p->isDIDesc()) {
      assert(nlinks < n, "too many DI caches in method");
      nmln* l = p->asDIDesc(this)->dependency();
      assert(l->isEmpty(), "should be empty");
      if (savedDIChildren[nlinks].notEmpty()) {
        nmln* ln = savedDIChildren[nlinks].next;        // cfront bug!
        ln->rebind(l);
        nmethod* target = findNMethod(ln);
        p->asDIDesc(this)->set_jump_addr(target->insts());
        assert(p->asDIDesc(this)->dependency()->notEmpty(),
               "should be rebound now");
      }
      nlinks++;
    }
  }
  MachineCache::flush_instruction_cache_for_debugging();
  assert(n == nlinks, "too few DI links in method");
}
# endif

PcDesc* nmethod::containingPcDescOrNULL(char* pc) {
  // returns PcDesc that is closest one before or == to pc, or 0 if
  // no stored pcDesc exists 
  // called a lot, so watch out for performance bugs
  assert(contains(pc), "nmethod must contain pc into frame");
  int32 offset = pc - insts();
  PcDesc* start = pcs();
  PcDesc* end = pcsEnd() - 1;

  // Skim the cream if only one pcDesc is present.
  if (start == end) return start; 
  assert(start < end, "no PcDescs to search");
  if (start->pc > offset)
    // in prologue; caller has to deal with this
    return 0;

  // binary search to find approx. location
  PcDesc* middle;
  int32 l = 0, h = end - start;
  do {
    // avoid pointer arithmetic -- gcc uses a division for PcDesc* - PcDesc*
    int32 m = l + (h - l) / 2;
    middle = &start[m];
    if (middle->pc < offset) {
      l = m + 1;
    } else {
      h = m - 1;
    }
  } while (middle->pc != offset && l < h);

  // may not have found exact offset, so search for closest match
  while (middle->pc <= offset && middle < end  ) middle++;
  while (middle->pc >  offset && middle > start) middle--;
  
  assert(start <= middle && middle <= end, "should have found a pcDesc");
# if GENERATE_DEBUGGING_AIDS
    if (CheckAssertions) {
      PcDesc* d = pcs();
      PcDesc* closest = d;
      for (; d <= end; d ++) {
        if (d->pc <= offset && (closest == 0 || closest->pc <= d->pc)) {
          closest = d;
        }
      }
      assert(closest == middle, "found different pcDesc");
    }
# endif

  return middle;
}

static PcDesc prologuePcDesc(0, 0, PrologueBCI);

PcDesc* nmethod::containingPcDesc(char* pc) {
  // returns PcDesc that is closest one before or == to pc
  PcDesc* p= containingPcDescOrNULL(pc);
  return p ? p : &prologuePcDesc;
}

fint nmethod::invocationCount() {
  if (useCount[id]) {
    // nmethod counts in prologue (to save space for count stubs)
    return useCount[id];
  } else {
    fint count = 0;
    for (nmln* l = linkedSends.next; l != &linkedSends; l = l->next) {
      NCodeBase* s = findThing(l);
      if (s->isCountStub()) count += ((CountStub*)s)->count();
    }
    return count;
  }
}

static int cmp_addrs(const void* p1,  const void* p2) {
  char** r1 = (char**) p1;
  char** r2 = (char**) p2;
  return *r1 - *r2;
}


bool nmethod::shouldNotRecompile() {
# ifdef SIC_COMPILER
  if (compiler() == NIC) return false;
  if (level() == MaxRecompilationLevels - 1)
    return true;                // no optimizable sends
  if (isYoung()) {
    if (invocationCount() > agingLimit() &&
        flags.trapCount < MapLoadTrapLimit) {
      // isn't really young anymore (but didn't trigger counter because it
      // has several callers)
      makeOld();
    } else if (nsends() > max(recompileLimit(0), 4 * agingLimit())) {
      // does a lot of sends - give it a chance anyway
    } else {
      // don't recompile yet - too young
      // but mark it for later recompilation
      makeToBeRecompiled();
      return true;
    }
  }
# endif
  return false; 
}


bool nmethod::mustNotRecompile() {
  // answers true if nm must not be recompiled (for non-performance-related
  // reasons)

  // never recompile new-compiled uncommon branches
  // don't recompile zombies (if they're zombies because of uncommon branch
  // traps, the recompiled nmethod already exists)
  if (isZombie() || isInvalid()) return true;

# ifdef SIC_COMPILER
  // the SIC doesn't compile access methods
  if (isAccess()) return true;
  if (version() >= MaxVersions && !isUncommonRecompiled())
    return true;
# endif

  // don't recompile VM-generated lookup error methods (breaks too many
  // assertions because method oop can change (new method generated during
  // lookup)
  methodMap* mm = (methodMap*)method()->map();
  return mm->file()->length() == 7
     &&  strncmp(mm->file()->bytes(), "<error>", 7) == 0;
}


bool nmethod::shouldRecompile() {
# ifdef SIC_COMPILER
  // recompile if uncommon
  if (isUncommonRecompiled()) return true;
  
  // don't recompile if highest level
  if (level() >= nstages) return false;

  // recompile if very small
  if (compiler() == NIC || isTiny()) return true;
# endif

  return false;
}


fint nmethod::ncallers() {
  // slow! need only approximate # callers, so clip at MaxCallers
  const fint MaxCallers = 10;
  AddressList callers(MaxCallers);
  fint i = 0;
  for (nmln* l = linkedSends.next; i < MaxCallers && l != &linkedSends; l = l->next, i++) {
    callers.append((char*)l);
  }
  if (i >= MaxCallers) return MaxCallers;
  qsort(callers.data_addr(), callers.length(), sizeof(char*), cmp_addrs);
  fint n = 0, len = callers.length();
  for (i = 0; i < len; ) {
    n++;
    nmethod* nm = ((nmln*)callers.nth(i))->asSender();
    while (++i < len && nm == ((nmln*)callers.nth(i))->asSender()) ;
  }
  return n;
}

fint nmethod::nsends(bool includeAll) {
  // add up the inlinable sends of the nmethod (i.e. those sent by inline
  // caches with comparing stubs); if includeAll, also count non-inlinable
  // sends
  fint nsends = 0;
  bool isNIC = compiler() == NIC;
  for (addrDesc* a = locs(), *aend = locsEnd(); a < aend; a++) {
    if (a->isSendDesc()) {
      sendDesc* sd = a->asSendDesc(this);
      if (!sd->isUninlinable()) {
        nsends += sd->nsends();
      } else if (isNIC && sd->countType() == Counting) {
        // must be a method containing _Restart
        nsends += sd->nsends();
      } else if (isNIC) {
        // NIC methods have no count stubs (to save space) but count the
        // # of invocations; assume all sends in NIC method are executed
        // once per execution of the method
        nsends += useCount[id];
      } else if (includeAll) {
        nsends += sd->nsends();
      }
    }
  }
  return nsends;
}


bool nmethod::isTiny() {
# ifdef SIC_COMPILER
  // is this a "tiny" nmethod, i.e. is it likely to be small when inlined?
  if (isAccess()) return true;
  if (compiler() == NIC) {
    // the NIC's code is large because it has many inline caches, so look
    // at the source
    fint len = ((methodMap*)method()->map())->codes()->length();
    fint max = key.receiverMap()->is_block() ?
                  TinyBlockSourceSize : TinyFnSourceSize;
    if  (len <= max) return true;
  } else {
    fint len = instsLen() - oopSize * PrologueSize;
    if (len < TinyFnObjSize) return true;
  }

  // try this last because it's relatively expensive
  return isCheapMessage((stringOop)key.selector);
# else
  return false;
# endif
}






// Memory operations: return true if need to inval cache

bool nmethod::scavenge_contents() {
  // scavenge all locations
  bool needToInvalICache = OopNCode::scavenge_contents();
  
  // do this after OopNCode::scavenge_contents, since it resets rememberLink
  key.scavenge_contents();
  FOR_MY_CODETABLE_ENTRIES(e)
    e->key.scavenge_contents();
  scopes->scavenge_contents();
  check_store();

  return needToInvalICache;
}

void nmethod::relocate() {
  key.relocate();
  FOR_MY_CODETABLE_ENTRIES(e)
    e->key.relocate();
  scopes->relocate();
  OopNCode::relocate();
}

bool nmethod::switch_pointers(oop from, oop to,
                              nmethodBList* nmethods_to_invalidate) {
  key.switch_pointers(from, to);
  FOR_MY_CODETABLE_ENTRIES(e)
    e->key.switch_pointers(from, to);
  scopes->switch_pointers(from, to, nmethods_to_invalidate);
  check_store();
  return OopNCode::switch_pointers(from, to, nmethods_to_invalidate);
}

void nmethod::gc_mark_contents() {
  key.gc_mark_contents();
  FOR_MY_CODETABLE_ENTRIES(e)
    e->key.gc_mark_contents();
  OopNCode::gc_mark_contents();
  scopes->gc_mark_contents();
}

bool nmethod::gc_unmark_contents() {
  key.gc_unmark_contents();
  FOR_MY_CODETABLE_ENTRIES(e)
    e->key.gc_unmark_contents();
  scopes->gc_unmark_contents();
  return OopNCode::gc_unmark_contents();
}

bool nmethod::code_oops_do(oopsDoFn f) {
  key.oops_do(f);
  FOR_MY_CODETABLE_ENTRIES(e)
    e->key.oops_do(f);
  scopes->oops_do(f);
  check_store();
  return OopNCode::code_oops_do(f);
}

bool nmethod::verify() {
  bool r = true;
  ResourceMark rm;

  r &= OopNCode::verify2("nmethod");
  
  if (insts() != (char*)(this + 1)) {
    error1("nmethod at 0x%lx has incorrect insts pointer", this);
    r = false;
  }
  if (!Memory->code->contains(this)) {
    error1("nmethod at 0x%lx not in zone", this);
    r = false;
  }
  if (!zoneLink.verify_list_integrity()) {
    lprintf("\tof zoneLink of nmethod 0x%lx\n", this);
    r = false;
  }
  { FOR_MY_CODETABLE_ENTRIES(e)
      if (e->nm != this) {
        error1("bad code table link for nmethod %#lx\n", this);
        r = false;
      }
  }
  bool isAligned = (frame_size & (frame_word_alignment-1)) == 0;
  if (!isAligned) {
    lprintf("nmethod at %#lx: frame size is not multiple of %d words\n",
           (long unsigned)this,
           frame_word_alignment);
    r = false;
  }
  if (codeTableLink != 0) {
    nmethod *tableResult =
      isDebug() ? Memory->code->debugTable->lookup(key) :
                  Memory->code->table     ->lookup(key);
    if (tableResult != this) {
      error1("nmethod at %#lx: code table lookup failed", this);
      r = false;
    }
  }
  if (!key.verify()) {
    lprintf("\tof key of nmethod 0x%lx\n", this);
    r = false;
  }
  { FOR_MY_CODETABLE_ENTRIES(e)
      if (!e->key.verify()) {
        lprintf("\tof code table key %#lx of nmethod 0x%lx\n",
               (long unsigned)&e->key, (long unsigned)this);
        r = false;
      }
  }
  if (!linkedSends.verify_list_integrity()) {
    lprintf("\tof linkedSends of nmethod 0x%lx\n", this);
    r = false;
  }
  if (!diLink.verify_list_integrity()) {
    lprintf("\tof diLink of nmethod 0x%lx\n", this);
    r = false;
  }
  r &= scopes->verify();

  for (PcDesc* p = pcs(); p < pcsEnd(); p++) {
    if (! p->verify(this)) {
      lprintf("\t\tin nmethod at %#lx (pcs)\n", this);
      r = false;
    }
  }
  
  // more checks in ncode::verify called above
  bool shouldBeDI = diLink.notEmpty();
  for (addrDesc* l = locs(); l < locsEnd(); l++) {
    if (l->isDIDesc()) {
      shouldBeDI = true;
    }
  }
  
  if (shouldBeDI && !isDI()) {
    error1("nmethod %#lx should be marked isDI", this);
    r = false;
  } else if (!shouldBeDI && isDI()) {
    error1("nmethod %#lx should not be marked isDI", this);
    r = false;
  }

  if (! key.receiverMap()->is_block() ) {
    for (nmln* d = deps(); d < depsEnd(); d++) {
      if (! d->verify_list_integrity()) {
        lprintf("\tin nmethod at %#lx (deps)\n", this);
        r = false;
      }
    }
  }
  
  if (frame_chain != NoFrameChain) {
    error1("nmethod %#lx has non-zero frame chain value", this);
    r = false;
  }
  
  if (findNMethod( instsEnd() - oopSize) != this) {
    error1("findNMethod did not find this nmethod (%#lx)", this);
    r = false;
  }
  return r;
}


// Printing operations

void nmethod::print() {
  ResourceMark rm;
  printIndent();
  lprintf("(nmethod*)%#lx", this);
  if (scopes->root()->isDataAccessScope()) {
    lprintf(" (data access)");
  } else if (scopes->root()->isDataAssignmentScope()) {
    lprintf(" (data assignment)");
  } else {
    lprintf(" for method %#lx", method());
  }
  lprintf(" { ");
  if (isYoung()) lprintf("YOUNG ");
  switch (compiler()) {
   case NIC: lprintf("NIC "); if (isImpureNIC()) lprintf("impure "); break;
   case SIC: lprintf("SIC level %ld ", level()); break;
   default:  lprintf("!?!unknown compiler!?! "); break;
  }
  if (version())           lprintf("v%d ", version());
  if (isDI())              lprintf("DI ");
  if (isZombie())          lprintf("zombie ");
  if (isInvalid())         lprintf("INVALID ");
  if (isDebug())           lprintf("DEBUG ");
  if (isToBeRecompiled())  lprintf("TBR ");
  if (isUncommon() || isUncommonRecompiled()) lprintf("UNCOMMON ");
  lprintf("}:\n");
 
  lprintf( "incoming_arg_count = %d\n", incoming_arg_count() );
  
  print_platform_specific_data();
  
  Indent ++;
  
  key.print();
  
  printIndent();
  lprintf("code table link: %#lx\n", codeTableLink);
  
  printIndent();
  lprintf("remember link: ");
  rememberLink.print();
  lprintf("\n");
  
  printIndent();
  lprintf("linked sends: ");
  linkedSends.print();
  lprintf("\n");
  
  printIndent();
  lprintf("di link: ");
  diLink.print();
  lprintf("\n");
  
  printIndent();
  lprintf("instructions (%ld bytes): %#lx,%#lx/i / x/%ldi %#lx\n",
         instsLen(), 
         insts(),
         instsEnd() - oopSize,
         instsLen() / oopSize,
         insts());
  printIndent(); lprintf("p ((nmethod*)%#lx)->printCode() \n", this);
  scopes->print();
  // printLocs();
  // printDeps();
  Indent --;
}

void nmethod::printCode() {
  ResourceMark m;       // in case methods get printed from gdb
  print_code(this, (char*)insts(), (char*)instsEnd());
}

# if  GENERATE_DEBUGGING_AIDS
void nmethod::printLocs() {
  ResourceMark m;       // in case methods get printed from gdb
  printIndent();
  lprintf("locations:\n");
  Indent ++;
  for (addrDesc* l = locs(); l < locsEnd(); l ++) l->print(this);
  Indent --;
}

void nmethod::printDeps() {
  ResourceMark m;       // in case methods get printed from gdb
  printIndent();
  lprintf("dependents:\n");
  Indent ++;
  for (nmln* n = deps(); n < depsEnd(); n ++) {
    printIndent();
    n->print();
    nmln* n1;
    for (n1= n->next;  n1 != n;  n1= n1->next) {
      oop *q= (oop*)(Memory->code->dZone->findStartOfBlock(n1));
      oop mapP= *q;
      if (Memory->really_contains(mapP)) {
        lprintf("  ");
        oop p= Memory->spaceFor(mapP)->find_oop_backwards(mapP);
        p->print();
        lprintf("\n");
        break;
      }
    }
    if (n1 == n) lprintf(" ??not linked to any map??\n");
  }
  Indent --;
}

void nmethod::printPcs() {
  ResourceMark m;       // in case methods get printed from gdb
  printIndent();
  lprintf("pc-bytecode offsets:\n");
  Indent ++;
  for (PcDesc* p = pcs(); p < pcsEnd(); p ++) p->print(this);
  Indent --;
}
#endif

bool nmethod::isNMethod(void* p) {
  return ((NCodeBase*)p)->vtbl_value() == ((nmethod*)0)->static_vtbl_value();
}

nmethod* nmethod::nmethodContaining(char* pc, char* likelyEntryPoint) {
  assert(Memory->code->contains(pc), "should contain address");
  if (likelyEntryPoint && Memory->code->contains(likelyEntryPoint)) {
    nmethod* result = nmethod_from_insts(likelyEntryPoint);
    if (result->contains(pc)) return result;
  }
  return findNMethod(pc);
}

nmethod* nmethod::findNMethod(void* start) {
  nmethod* m = Memory->code->findNMethod(start);
  assert(m->encompasses(start), "returned wrong nmethod");
  return m;
}

nmethod* nmethod::findNMethod_maybe(void* start) {
  nmethod* m = Memory->code->findNMethod_maybe(start);
  assert(!m || m->encompasses(start), "returned wrong nmethod");
  return m;
}

static inline bool includes(void* p, void* from, void* to) {
  return from <= p && p < to;
}

bool nmethod::encompasses(void* p) {
  return includes(p, this, this + 1) ||
         includes(p, deps(), depsEnd()) ||
         includes(p, insts(), instsEnd()) ||
         includes(p, locs(), locsEnd()) ||
         scopes->includes((ScopeDesc*) p) ||
         includes(p, pcs(), pcsEnd());
}


ScopeDesc* nmethod::correspondingScopeDesc(ScopeDesc* s) {
  // find scope corresponding to s; return 0 if not found
  ScopeDesc* scope = 0;

  FOR_EACH_SCOPE(scopes, c) {
    // compare c and its senders
    ScopeDesc *c1, *s1;
    for (c1= c, s1= s;
         c1 && s1 && c1->s_equivalent(s1);
         c1= c1->sender(), s1= s1->sender())
      ;
    if (c1 == 0 || s1 == 0) {
      // c corresponds to s
      assert(scope == 0, "found more than one scope");
      scope = c;
# if !GENERATE_DEBUGGING_AIDS
    if (!CheckAssertions) {
        break;
    }
# endif
    }
  }
  return scope;
}

# if  GENERATE_DEBUGGING_AIDS
PcDesc* nmethod::correspondingPC(ScopeDesc* sd, int32 bci) {
  // find the starting PC of this scope
  assert(scopes->includes(sd), "scope not in this nmethod");  
  int32 scope = scopes->offsetTo(sd);
  PcDesc *p, *end;
  for (p = pcs(), end = pcsEnd(); p < end; p ++) {
    if (p->scope == scope && p->byteCode == bci) break;
  }
  if (p < end ) {
    return p;
  } else {
    // no PC corresponding to this scope
    return 0;
  }
}
#endif


class sendDescFinder : public abstract_interpreter {
  // Find inline cache for the current byte code index of vf.
  // Note that this may return a primitive call "inline cache".
  // The receiver must be an unoptimized nmethod (no inlining).
  // This code depends on the structure of code generated by the NIC.
  // If wantIntrCheck, return the intr check primitive call rather than the
  // actual send; if !intrCheck, don't return intrCheck if possible
  // (e.g. if current position is a literal, returns intrCheck call anyway).
  
 public:
 
  bool wantIntrCheck;
  nmethod* nm;
  compiled_vframe* vf;
  PcDesc* p;
  PcDesc* pend;
  
  addrDesc* a;
  addrDesc* aend;
  
  char*     target;
  
  sendDesc* sd; 
   
 
  sendDescFinder(compiled_vframe* vf_arg, bool wantIntrCheck, nmethod* nm_arg);
  
  void find_it();
  bool advance_to_pcDesc_for_this_vmethod();
  void advance_to_addrDesc_for_an_inlineCache_in_this_pcDesc();
  void try_for_non_intrCheck_sendDesc();
  bool want_primitiveFailure_branch();
  void find_failure_sendDesc();
  void next_addrDesc_if_not_restart();
  
       
  // shouldn't stop at these
  
  void do_UNDIRECTED_RESEND_CODE() { ShouldNotReachHere(); }
  void do_DELEGATEE_CODE()         { ShouldNotReachHere(); }
  void do_LEXICAL_LEVEL_CODE()     { ShouldNotReachHere(); }
  void do_INDEX_CODE()             { ShouldNotReachHere(); }
  void do_READ_LOCAL_CODE()        { ShouldNotReachHere(); }
  void do_WRITE_LOCAL_CODE()       { ShouldNotReachHere(); }
  void do_POP_CODE()               { ShouldNotReachHere(); }
  
  void do_BRANCH_CODE()            { ShouldNotReachHere(); }
  void do_BRANCH_TRUE_CODE()       { ShouldNotReachHere(); }
  void do_BRANCK_FALSE_CODE()      { ShouldNotReachHere(); }
  void do_BRANCH_INDEXED_CODE()    { ShouldNotReachHere(); }
  
  void do_SEND_CODE()           { next_addrDesc_if_not_restart(); }
  void do_IMPLICIT_SEND_CODE()  { next_addrDesc_if_not_restart(); }
};


sendDescFinder::sendDescFinder(compiled_vframe* vf_arg, bool wci, nmethod* nm_arg) 
 : abstract_interpreter(vf_arg->method()) {
  vf= vf_arg;
  pc= vf->real_bci();
  wantIntrCheck= wci;
  nm= nm_arg;
  
  p=    nm->pcs();
  pend= nm->pcsEnd();
  a=    nm->locs();
  aend= nm->locsEnd();
}


void sendDescFinder::find_it() {
  for ( ;; ++p ) {
    bool cannotIncrementPAnymore = advance_to_pcDesc_for_this_vmethod();
    advance_to_addrDesc_for_an_inlineCache_in_this_pcDesc();
    
    try_for_non_intrCheck_sendDesc();

    if (a >= aend || !a->isCall()) ShouldNotReachHere(); // no addrDesc found

    sd= a->isPrimitive()  ? a->asPrimitiveSendDesc(nm) 
                          : a->asSendDesc(nm);
    
    PcDesc* sdpc= nm->containingPcDesc((char*)sd);
    if ( ( sdpc->byteCode == pc  ||   (pc == PrologueBCI && sdpc->byteCode == mi.firstBCI()))
    &&   sdpc->scope == p->scope) {
      // found the right sendDesc: bytecodes & scope match, or got first
      // intr check (which may be in bci 0 instead of prologue)
      break;
    }
    if (cannotIncrementPAnymore)
      fatal("cannot possibly work to keep iterating");
  }
  if ( want_primitiveFailure_branch() )
    find_failure_sendDesc();
}


bool sendDescFinder::advance_to_pcDesc_for_this_vmethod() { 
  if (pc == PrologueBCI) {
    // Allocate the PcDesc in the resource area. (fix this, Lars)
    p= NEW_RESOURCE_OBJ(PcDesc);
    p->pc = mi.firstBCI();  p->scope = 0;  p->byteCode = PrologueBCI;
    assert(p->containingDesc(nm)->method()->codes() == mi.codes_object,
           "oops");
    return true;
  }
  for (  ;  p < pend;  ++p) {
    if ( p->byteCode == pc
    &&   p->containingDesc(nm)->method()->codes() == mi.codes_object)
       return false;
  }
  fatal("no pcDesc found");
  return false; // avoid stupid warning
}    


void sendDescFinder::advance_to_addrDesc_for_an_inlineCache_in_this_pcDesc() {
  for ( ; a < aend;  a++ ) {
    if ( !a->isCall()  ||  a->offset() < p->pc )
      continue;
    target= a->referent(nm);
      
    // This is probably the send we want; just make sure that lookup
    // miss code etc doesn't mess things up.
    // In the prologue, only InterruptCheck counts
    // NB: if receiver isDebug(), prologue doesn't have intr check
    // because there's one in the 1st byte code    
    
    if ( pc != PrologueBCI 
    ||   target == first_inst_addr(interruptCheck))
      return;
  }
  fatal("no addrDesc found");
}


void sendDescFinder::try_for_non_intrCheck_sendDesc() {
  if ( nm->isDebug()  // must have extra interruptChecks to bypass
  &&  !wantIntrCheck 
  &&  target == first_inst_addr(interruptCheck))
    interpret_bytecode();  // will try for non-intrCheck sendDesc
}


void sendDescFinder::next_addrDesc_if_not_restart() {
  // skip single-stepping code (interrupt check is at beginning of
  // every byte code, before the real send)

  // If send is a local access and !UseLocalAccessBytecodes
  // no sendDesc has been generated;
  // too tricky to check here

  // a is an interrupt check; the next addrDesc must be the call
  // we want, except if it is a _Restart
    
  is.index= mi.map()->get_index_at(pc);
  
  if (get_selector() == VMString[_RESTART]) 
    return; // no real sendDesc to find
    
  // local send (in debug method) will not have a matching addrDesc
  
  if ( &a[1] < aend 
  &&    a[1].isCall()
  &&    a[1].offset() >= p->pc)
    a++;  // the next one is the one we want
}    


bool sendDescFinder::want_primitiveFailure_branch() {
  assert(vf->fr->is_aligned(), "");
  return  a->isPrimitive()  &&  !vf->is_uncommonTrap()  &&  !vf->is_primCall();
}


void sendDescFinder::find_failure_sendDesc() {
  for (  ;  a < aend  &&  !a->isSendDesc();  ++a) 
    ;
  assert(a < aend, "did not find failure branch");
  sd= a->asSendDesc(nm);
  assert(   wantIntrCheck
      ||    sd->selector() == VMString[VALUE_WITH_]
      ||    sd->selector() == VMString[PRIMITIVE_FAILED_ERROR_NAME_],
          "found wrong failure branch");
}



sendDesc* nmethod::sendDescFor(compiled_vframe* vf, bool wantIntrCheck) {
  // Find inline cache for the current byte code index of vf.
  // Note that this may return a primitive call "inline cache".
  // The receiver must be an unoptimized nmethod (no inlining).
  // This code depends on the structure of code generated by the NIC.
  // If wantIntrCheck, return the intr check primitive call rather than the
  // actual send; if !intrCheck, don't return intrCheck if possible
  // (e.g. if current position is a literal, returns intrCheck call anyway).
  if (compiler() != NIC)
    ShouldNotReachHere(); // cannot find sendDesc in optimized method
    
  sendDescFinder sdf(vf, wantIntrCheck, this);
  sdf.find_it();
  return sdf.sd;
}


Map* nmethod::blockMapFor(blockOop bl) {
  // bl is a block that has been remapped; find a block reference in our
  // code which refers to the "same" block (different map, but same value
  // method)
  assert_block(bl, "not a block");
  if (compiler() != NIC) fatal("cannot find blocks in optimized method");
  oop valueMethod = bl->value();
  oop foundBlk = 0;
  for (addrDesc* p = locs(), *pend = locsEnd(); p < pend; p++) {
    if (!p->isOop()) // not no oops here
      continue;
    oop blk = oop(p->referent(this));
    if (blk->is_block()) {
      oop method2 = blockOop(blk)->value();
      if (valueMethod == method2) {
        assert(foundBlk == 0 || foundBlk == blk, "duplicate block found");
        foundBlk = blockOop(blk);       // found it
# if !GENERATE_DEBUGGING_AIDS
    if (!CheckAssertions) {
      break;
    }
# endif
      }
    }
  }
  if (method() == valueMethod) {
    // it's the receiver block
    assert(foundBlk == 0 || foundBlk->map() == key.receiverMap(),
           "can't handle duplicate blocks");
    return key.receiverMap();
  }
  if (foundBlk) return foundBlk->map();
  ShouldNotReachHere(); // didn't find block
  return 0;
}

addrDesc* nmethod::addrDesc_at(char* pc) {
  // return addrDesc for pc or 0 if none
  assert(insts() <= pc && pc < instsEnd(), "not in this nmethod");
  fint offset = pc - insts();
  for (addrDesc* p = locs(), *pend = locsEnd(); p < pend; p++) {
    if (p->offset() == offset) return p;
  }
  return 0;
}


bool  nmethod::has_frame_at(char* pc) {
  if (isAccess()) return false;
  if (compiler() == NIC) {
    // if the save instruction at frameCreationOffset - word
    // has been overwriten follow the branch to find the save.
    int32* save_inst = (int32*)(insts() + frameCreationOffset- sizeof(long));
    char* save_addr = address_of_overwritten_NIC_save_instruction(save_inst);
    if ( save_addr != 0 ) // save was moved, is at save_addr
      return  pc >= insts() + frameCreationOffset  &&  pc != save_addr;
  }
  return pc >= insts() + frameCreationOffset;
}


bool  nmethod::in_self_code_at(char* pc) {
  PcDesc* pd = containingPcDescOrNULL(pc);
  if (pd == 0) return false;
  return  pd->byteCode != PrologueBCI
      &&  pd->byteCode != EpilogueBCI;
}

void nmethod_init() {
  // make sure you didn't forget to adjust the filler fields
  assert(sizeof(nmFlags) <= 4, "nmFlags occupies more than a word");
}


static nmethod* constructDoItMethod_cont(oop receiver, oop method) {
  ResourceMark rm;
  compilingLookup L( receiver,
                     VMString[DO_IT],
                     0,     // delegatee
                     receiver, // method holder
                     0,     // vframe
                     sendDesc::first_sendDesc(),
                     0,     // DIDesc
                     false );  // don't want debug version
  L.setResult(method);
  nmethod *nm= L.lookupNMethod();
  nm->makeZombie(); // throw away as soon as it is off the stack
  return nm;
}

nmethod* constructDoItMethod(oop receiver, oop method) {
  return switchToVMStack(receiver, method, constructDoItMethod_cont);
}


# if  GENERATE_DEBUGGING_AIDS
// for debugging: given a descOffset (e.g. from a block), findOffset finds
// all nmethods that have such a descOffset
static fint offset_to_find;
static void findOffsetFn(nmethod* nm) {
  nmethodScopes* s = nm->scopes;
  FOR_EACH_SCOPE(s, scope) {
    if (scope->offset() == offset_to_find) {
      lprintf("nmethod* %#lx\n", nm);
      scope->print();
       return;
    }
  }
}

void findOffset(fint offset) {
  ResourceMark rm;
  offset_to_find = offset;
  Memory->code->nmethods_do(findOffsetFn);
}

#endif

# else // defined(FAST_COMPILER) || defined(SIC_COMPILER)

void nmethod_init() {}

# endif // defined(FAST_COMPILER) || defined(SIC_COMPILER)
